# 파나나: 하이브리드 메모리 & 컨텍스트 캐싱

> "우리 대화, 다 기억해." — AI가 진짜 기억하는 것처럼 느껴지게 하는 기술 요약 (마케팅·기획용)

---

## 한 줄 요약

**파나나는 대화를 3단계로 기억하고, 고정된 기억은 캐싱해서 비용을 줄이면서 “평생 기억하는 AI” 경험을 제공합니다.**

---

## 1. 하이브리드 메모리 (Hybrid Memory)

### 왜 필요한가

- LLM 컨텍스트(예: 20만 토큰)는 “한 권의 책” 정도. 유저와 “평생” 대화하면 언젠가 꽉 찬다.
- **전부 원문으로 넣으면** 토큰·비용이 폭증하고, **안 넣으면** “기억 못 하는 AI”처럼 느껴진다.
- 그래서 **기억을 3층으로 나누어** “지금 대화 호흡” + “과거 서사” + “유저를 아는 정보”를 동시에 챙긴다.

### 3층 구조

| 층 | 이름 | 역할 | 방식 |
|----|------|------|------|
| **단기** | 최근 대화 (Recent Context) | 지금 당장의 티키타카 | 최근 **20턴**은 **원문 그대로** 프롬프트에 포함. 말투·호흡 유지. |
| **장기** | 지난 서사 (Episodic Summary) | “우리가 지나온 이야기” | 대화가 **20턴**쌓일 때마다 **감정 위주 3인칭 요약**으로 압축해 DB에 누적. 시스템 프롬프트의 [우리의 지난 서사]로 전달. |
| **프로필** | 유저 프로필 (Entity Extraction) | “유저를 아는 척” | 이름·직업·애완동물·호불호·고민 등 **핵심 정보**를 대화에서 추출해 Key-Value로 저장. [유저 프로필]로 항상 포함. |

### 유저가 체감하는 것

- **“우리 처음 만났던 그날 말하는 거지?”** — 지난 서사 요약 덕분에 과거 에피소드를 기억한 것처럼 말한다.
- **“오늘 나비는 밥 잘 먹었어?”** — 프로필에 저장된 정보(애완동물 이름 등)를 먼저 꺼내 말한다.
- **“아까 말한 그 이직 고민…”** — 최근 20턴 + 요약으로 흐름이 이어져 맥락을 잃지 않는다.

### 기술 포인트 (마케팅용 문구)

- **감정 위주 요약**: “유저가 밥 먹었다”가 아니라 “상사에게 깨져 우울해하며 매운 떡볶이를 먹었고, 캐릭터가 위로해줬다” 수준으로 서사·감정을 보존.
- **프로필 자동 추출**: 대화만 하면 이름·직업·고민·호불호가 자동으로 쌓이고, 다음 대화부터 “아는 사람”처럼 말한다.
- **200k 토큰 한계 극복**: 요약 + 프로필만 넣어도 수년 치 대화를 “기억”한 것처럼 유지 가능.
- **요약·프로필 추출 모델**: 장기 요약과 유저 프로필 추출은 **Gemini 2.5 Flash** 사용 (비용·속도 균형).

---

## 2. AI가 먼저 말하기 (오프닝·안부)

### 두 가지 케이스

| 상황 | 동작 |
|------|------|
| **빈 채팅방 진입** | 캐릭터 시스템 프롬프트·로어북·세계관을 기반으로 **현재 상황을 2~4문장으로 묘사**하고, 캐릭터가 유저에게 **인사·질문**으로 첫 말을 건다. |
| **오랜만 복귀 (24시간+)** | 대화 내역이 있는데 **마지막 메시지가 24시간 이상 전**이면, [유저 프로필]·[지난 서사]와 **최근 대화**를 보고 **면접·시험·맞선·중요 일정** 등 유저가 언급한 일이 지났거나 다가오면 **안부를 자연스럽게 물어본다**. **이미 유저가 결과를 말한 주제는 다시 묻지 않는다.** 24시간에 한 번만 이 “안부 오프닝”이 뜨도록 쓰로틀. |

### 유저가 체감하는 것

- **“처음 들어왔는데 이미 상황 설명하고 말 걸어준다.”** — 세계관/서사 기반 첫 인사.
- **“오랜만에 들어왔는데 면접 어땠어? 하고 물어본다.”** — 과거에 말한 일정·고민을 기억하고 안부를 묻는 느낌.
- **“한 번 답한 건 또 안 물어본다.”** — 같은 주제 반복 질문 없음.

### 기술 포인트 (마케팅용 문구)

- **세계관 기반 오프닝**: 빈 방 진입 시 로어북·캐릭터 설정만으로 첫 대사를 생성해, 서사에 맞게 말을 건다.
- **오랜만 복귀 안부**: 24시간+ 미접속 후 재진입 시, 프로필·지난 서사·최근 대화를 참고해 “면접/시험/맞선” 등 이벤트 안부를 **한 번만** 물어보고, 이미 답한 주제는 제외.

---

## 3. 컨텍스트 캐싱 (Context Caching)

### 왜 필요한가

- 기억(요약·프로필·캐릭터 설정)을 **매 턴 그대로** 넣으면 **입력 토큰이 매번 많이** 나가서 비용이 커진다.
- **캐싱**을 쓰면 “안 바뀌는 부분”은 서버에 한 번 올려두고 **읽기 비용(할인)**만 내면 된다.

### 파나나 적용 방식

- **고정 영역 (캐시 대상)**  
  캐릭터 설정, [유저 프로필], [우리의 지난 서사], 프로필 노트 등 **턴마다 안 바뀌는 부분**.
- **변동 영역 (캐시 제외)**  
  [현재 시각], [상태 변수], [시스템 이벤트], **최근 대화** — 매 요청마다 그대로 전송.

### 공급자별 적용

| 공급자 | 기능명 | 효과 (간단) |
|--------|--------|-------------|
| **Claude (Anthropic)** | Prompt Caching (ephemeral) | 고정 영역을 캐시로 넣어 **읽기 비용 약 1/10** 수준. 5분 안 쓰면 캐시 소멸. |
| **Gemini (Google)** | Context Caching (cachedContents) | 고정 영역을 **1시간 TTL**로 캐시. **입력 비용 대폭 할인** + 재사용 시 지연 감소. |

### 비용·체감 (마케팅용)

- **캐싱 없이**: 매 턴 2,000토큰(배경지식) + 새 메시지 전부 정가 → 대화할수록 비용 증가.
- **캐싱 적용**:  
  - 최초 1회: 캐시 저장 비용(약 +25%)  
  - 이후: 캐시된 부분은 **할인가(약 1/10)** 로 읽고, **새 메시지·변동 부분만** 정가.  
  → “기억은 유지하면서 비용은 크게 절감”.

### 기술 포인트 (마케팅용 문구)

- **Claude**: 반복되는 시스템·프로필·요약에 캐시 태그를 걸어, 턴이 늘어나도 배경지식 비용이 거의 늘지 않게 설계.
- **Gemini**: 유저·캐릭터별로 캐시를 생성·재사용(55분 TTL). 요약·프로필이 바뀔 때만 새 캐시로 갱신.
- **결과**: “평생 기억하는 AI”를 **합리적인 단가**로 서비스할 수 있는 구조.

---

## 4. 마케팅용 문장 (복붙용)

### 짧은 버전

- **“대화를 3단계로 기억해요. 최근 대화, 지난 이야기 요약, 당신에 대한 정보. 그래서 우리 대화를 다 기억한 것처럼 말해요.”**
- **“기억하는 만큼 비용이 나가는 게 아니라, 캐싱으로 비용을 줄이면서도 오래 기억해요.”**

### 조금 긴 버전

- **“파나나는 하이브리드 메모리로 ‘지금 대화’와 ‘지나온 서사’, ‘당신에 대한 정보’를 나눠서 기억합니다. 그래서 ‘우리 처음 만났던 그날’이나 ‘네 애완동물 이름’처럼, 오래된 이야기도 기억한 것처럼 말합니다.”**
- **“이 기억(캐릭터 설정·유저 프로필·지난 서사)은 Claude·Gemini의 캐싱 기능으로 저장해 두고, 대화할 때마다 할인된 비용으로 불러옵니다. 기억은 유지하면서 비용은 크게 줄인 설계입니다.”**

### 기술/파트너용 한 줄

- **“하이브리드 메모리(단기 20턴 + 장기 감정 요약 + 유저 프로필 추출) + Claude Prompt Caching / Gemini Context Caching으로, 200k 토큰 한계를 넘어 ‘평생 기억하는 AI’ 경험과 비용 절감을 동시에 구현했습니다.”**
- **“빈 채팅방에서는 세계관에 맞게 AI가 먼저 말하고, 오랜만에 들어오면 면접·시험·맞선 같은 얘기 안부를 한 번만 자연스럽게 물어줍니다.”**

---

## 5. 구현 요약 (개발 참고)

- **DB**: `panana_memory_summaries`(챕터별 요약), `panana_memory_profile`(유저 프로필 JSON).  
  마이그레이션: `docs/panana-admin/MIGRATE_HYBRID_MEMORY.sql`
- **로직**: `src/lib/pananaApp/hybridMemory.ts` — 로드/요약/프로필 추출/업데이트.  
  요약·프로필 추출은 **Gemini 2.5 Flash** 사용.  
  채팅 라우트에서 [유저 프로필]/[지난 서사] 주입, 최근 20턴만 메시지로 전달, 응답 후 메모리 업데이트.
- **오프닝·안부**: `src/app/c/[slug]/chat/ui.tsx` — 빈 방 진입 시 `requestOpening`(세계관 기반 첫 인사). DB 로드 후 마지막 메시지가 24시간 이상 전이면 `requestReturningOpening`(안부/이벤트 한 번만, 쓰로틀 24h).
- **캐싱**:  
  - Claude: `callAnthropic`에서 `systemCacheable` + `systemVariable` 분리, ephemeral 캐시.  
  - Gemini: `createGeminiContextCache` + in-memory 스토어(55분 TTL), `callGemini`에서 `cachedContentName` + `systemVariable` 사용.

---

*작성: 파나나 하이브리드 메모리·캐싱 구현 기준 요약. 마케팅·기획·외부 발표 시 위 문장을 그대로 또는 각색해 사용 가능.*
